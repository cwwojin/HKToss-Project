{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # 최대 행 수를 None으로 설정하여 모든 행이 출력되도록 함\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# # 최대 열 수를 None으로 설정하여 모든 열이 출력되도록 함\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# # 행과 열의 출력 옵션을 원래 상태로 되돌림\n",
    "# pd.reset_option('display.max_rows')\n",
    "# pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = '.tmp/dataset/train_set.csv'\n",
    "FILE_PATH = \".tmp/dataset/dataset_train.csv\"\n",
    "data = pd.read_csv(FILE_PATH)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # 시각화를 위한 Matplotlib 라이브러리\n",
    "import pandas as pd  # 데이터 프레임을 다루기 위한 pandas 라이브러리\n",
    "import seaborn as sns  # 시각화를 위한 Seaborn 라이브러리\n",
    "from catboost import CatBoostClassifier  # CatBoost 분류 모델\n",
    "from lightgbm import LGBMClassifier  # LightGBM 분류 모델\n",
    "from sklearn.ensemble import RandomForestClassifier  # 랜덤 포레스트 분류 모델\n",
    "from sklearn.linear_model import LogisticRegression  # 로지스틱 회귀 모델\n",
    "from sklearn.metrics import roc_curve  # 모델 성능 평가를 위한 함수들\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")  # 데이터셋을 학습용과 검증용으로 나누기 위한 함수\n",
    "from sklearn.neural_network import MLPClassifier  # MLP (다층 퍼셉트론) 분류 모델\n",
    "from sklearn.preprocessing import (  # 데이터 스케일링을 위한 StandardScaler\n",
    "    StandardScaler,\n",
    ")\n",
    "from xgboost import XGBClassifier  # XGBoost 분류 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 처리 및 모델 학습 모듈화\n",
    "\n",
    "> load_and_split_data: 데이터 로드와 학습/테스트 분할.\n",
    "\n",
    "> scale_data: 학습 데이터와 테스트 데이터 스케일링.\n",
    "\n",
    "> train_and_evaluate_model: 모델 학습 및 예측.\n",
    "\n",
    "> evaluate_performance: 성능 지표 계산.\n",
    "\n",
    "> plot_roc_curve: ROC-AUC 그래프 시각화.\n",
    "\n",
    "> plot_confusion_matrix: 혼동 행렬 시각화.\n",
    "\n",
    "> plot_feature_importance: 피처 중요도 시각화.\n",
    "\n",
    "> run_model_pipeline 함수로 하나의 모델 실행 과정을 전체적으로 처리.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 분할 함수\n",
    "def load_and_split_data(\n",
    "    file_path, target_column=\"TARGET\", test_size=0.3, random_state=42\n",
    "):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # 범주형 칼럼에 대해 One Hot Encoding 적용\n",
    "    object_col = data.select_dtypes(include=\"object\").columns\n",
    "    ohe_df = pd.get_dummies(data, columns=object_col)\n",
    "    bool_columns = ohe_df.select_dtypes(include=\"bool\").columns\n",
    "    ohe_df[bool_columns] = ohe_df[bool_columns].applymap(lambda x: 1 if x else 0)\n",
    "\n",
    "    X = ohe_df.drop(columns=[target_column])\n",
    "    y = ohe_df[target_column]\n",
    "\n",
    "    return train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "\n",
    "# 데이터 스케일링 함수\n",
    "def scale_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "\n",
    "# 모델 학습 및 예측 함수\n",
    "def train_and_evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    return y_pred, y_pred_proba\n",
    "\n",
    "\n",
    "# 성능 평가 함수\n",
    "def evaluate_performance(y_test, y_pred, y_pred_proba):\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "# ROC Curve 시각화 함수\n",
    "def plot_roc_curve(y_test, y_pred_proba, roc_auc):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=\"ROC Curve (area = %0.2f)\" % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 혼동 행렬 시각화 함수\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 피처 중요도 시각화 함수\n",
    "def plot_feature_importance(model, feature_names, top_n=3):\n",
    "    if hasattr(model, \"coef_\"):\n",
    "        importance = model.coef_[0]\n",
    "    elif hasattr(model, \"feature_importances_\"):\n",
    "        importance = model.feature_importances_\n",
    "    else:\n",
    "        print(\"Feature importance is not available for this model.\")\n",
    "        return\n",
    "\n",
    "    importance_df = pd.DataFrame({\"Feature\": feature_names, \"Importance\": importance})\n",
    "    importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    top_features = importance_df.head(top_n)\n",
    "    bottom_features = importance_df.tail(top_n)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.barplot(x=\"Importance\", y=\"Feature\", data=top_features)\n",
    "    plt.title(f\"Top {top_n} Feature Importance\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.barplot(x=\"Importance\", y=\"Feature\", data=bottom_features)\n",
    "    plt.title(f\"Bottom {top_n} Feature Importance\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 전체 실행 함수 (각 모델에 대해 호출할 수 있는 함수)\n",
    "def run_model_pipeline(model, file_path, top_n=3):\n",
    "    # 1. 데이터 로드 및 전처리, 분할\n",
    "    X_train, X_test, y_train, y_test = load_and_split_data(file_path)\n",
    "\n",
    "    # 2. 데이터 스케일링\n",
    "    X_train_scaled, X_test_scaled = scale_data(X_train, X_test)\n",
    "\n",
    "    # 3. 모델 학습 및 예측\n",
    "    y_pred, y_pred_proba = train_and_evaluate_model(\n",
    "        model, X_train_scaled, y_train, X_test_scaled, y_test\n",
    "    )\n",
    "\n",
    "    # 4. 성능 평가\n",
    "    roc_auc = evaluate_performance(y_test, y_pred, y_pred_proba)\n",
    "\n",
    "    # 5. ROC Curve 시각화\n",
    "    plot_roc_curve(y_test, y_pred_proba, roc_auc)\n",
    "\n",
    "    # 6. 혼동 행렬 시각화\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # 7. 피처 중요도 시각화\n",
    "    plot_feature_importance(model, X_train.columns, top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "run_model_pipeline(logistic_model, FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 포레스트\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, random_state=42, class_weight=\"balanced\"\n",
    ")\n",
    "run_model_pipeline(rf_model, FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_and_split_data(FILE_PATH)\n",
    "X_train_scaled, X_test_scaled = scale_data(X_train, X_test)\n",
    "scale_pos_weight = len(y_train) / sum(y_train)  # 양성 클래스 비율 계산\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False, eval_metric=\"logloss\", scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "\n",
    "run_model_pipeline(xgb_model, FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_and_split_data(FILE_PATH)\n",
    "X_train_scaled, X_test_scaled = scale_data(X_train, X_test)\n",
    "lgb_model = LGBMClassifier(class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "run_model_pipeline(lgb_model, FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CatBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    class_weights=[1, len(y_train) / sum(y_train)],\n",
    "    random_state=42,\n",
    "    verbose=100,\n",
    ")\n",
    "\n",
    "run_model_pipeline(CB_model, FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "run_model_pipeline(MLP_model, FILE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
